#!/usr/bin/env python3
"""
analyze_memory_suite_results.py

Reads a JSON results file from pseudo_mamba_memory_suite.py and prints:
    - Per (task, horizon, controller): mean / std of final_avg_return across seeds
    - Best controller per (task, horizon)
    - Optional CSV export
"""

import argparse
import json
import os
from collections import defaultdict
from typing import Dict, Any, List, Tuple

import math


def parse_args() -> argparse.Namespace:
    p = argparse.ArgumentParser()
    p.add_argument(
        "--results",
        type=str,
        default="results/memory_suite_v1.json",
        help="Path to JSON results file generated by pseudo_mamba_memory_suite.py",
    )
    p.add_argument(
        "--csv-out",
        type=str,
        default=None,
        help="Optional CSV output path for further plotting.",
    )
    return p.parse_args()


def load_results(path: str) -> List[Dict[str, Any]]:
    if not os.path.exists(path):
        raise FileNotFoundError(f"Results file not found: {path}")
    with open(path, "r") as f:
        data = json.load(f)
    if not isinstance(data, list):
        raise ValueError("Results file must contain a list of run dicts.")
    return data


def aggregate(results: List[Dict[str, Any]]):
    # key: (task, horizon, controller)
    buckets: Dict[Tuple[str, int, str], List[float]] = defaultdict(list)
    durations: Dict[Tuple[str, int, str], List[float]] = defaultdict(list)

    for r in results:
        if r.get("status") != "ok":
            continue
        task = r["task"]
        horizon = int(r.get("horizon", 0))
        controller = r["controller"]
        final_ret = float(r.get("final_avg_return", float("nan")))
        if math.isnan(final_ret):
            continue
        key = (task, horizon, controller)
        buckets[key].append(final_ret)
        durations[key].append(float(r.get("duration_sec", 0.0)))

    summary = []
    for key, vals in buckets.items():
        task, horizon, controller = key
        mean_ret = sum(vals) / len(vals)
        if len(vals) > 1:
            var = sum((v - mean_ret) ** 2 for v in vals) / (len(vals) - 1)
            std_ret = math.sqrt(var)
        else:
            std_ret = 0.0
        mean_dur = sum(durations[key]) / max(len(durations[key]), 1)
        summary.append(
            {
                "task": task,
                "horizon": horizon,
                "controller": controller,
                "n": len(vals),
                "mean_final_return": mean_ret,
                "std_final_return": std_ret,
                "mean_duration_sec": mean_dur,
            }
        )

    # sort by task, horizon, controller
    summary.sort(key=lambda d: (d["task"], d["horizon"], d["controller"]))
    return summary


def print_table(summary: List[Dict[str, Any]]):
    if not summary:
        print("No successful runs to summarize.")
        return

    print("\n" + "=" * 100)
    print("BENCHMARK COMPARISON TO REFERENCE BASELINE")
    print("=" * 100)
    
    print(f"\n{'Task':<16} {'Hor':>6} {'Controller':<14} {'N':>3} {'MeanRet':>8} {'StdRet':>8} {'Dur(s)':>8}")
    print("-" * 100)
    for row in summary:
        print(
            f"{row['task']:<16} {row['horizon']:>6} {row['controller']:<14} "
            f"{row['n']:>3} {row['mean_final_return']:>8.3f} {row['std_final_return']:>8.3f} "
            f"{row['mean_duration_sec']:>8.1f}"
        )

    # Best controller per (task, horizon)
    print("\n" + "=" * 100)
    print("BEST CONTROLLER PER TASK / HORIZON (by mean_final_return)")
    print("=" * 100)
    grouped: Dict[Tuple[str, int], List[Dict[str, Any]]] = defaultdict(list)
    for row in summary:
        grouped[(row["task"], row["horizon"])].append(row)

    print(f"\n{'Task':<16} {'Hor':>6} {'BestCtrl':<14} {'MeanRet':>8} {'StdRet':>8}")
    print("-" * 60)
    for (task, horizon), rows in sorted(grouped.items(), key=lambda x: (x[0][0], x[0][1])):
        best = max(rows, key=lambda r: r["mean_final_return"])
        print(
            f"{task:<16} {horizon:>6} {best['controller']:<14} "
            f"{best['mean_final_return']:>8.3f} {best['std_final_return']:>8.3f}"
        )
    print("=" * 100)


def save_csv(summary: List[Dict[str, Any]], path: str):
    import csv

    os.makedirs(os.path.dirname(path) or ".", exist_ok=True)
    fieldnames = [
        "task",
        "horizon",
        "controller",
        "n",
        "mean_final_return",
        "std_final_return",
        "mean_duration_sec",
    ]
    with open(path, "w", newline="") as f:
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        writer.writeheader()
        for row in summary:
            writer.writerow(row)
    print(f"\nCSV saved to: {path}")


def main():
    args = parse_args()
    results = load_results(args.results)
    summary = aggregate(results)
    print_table(summary)
    if args.csv_out:
        save_csv(summary, args.csv_out)


if __name__ == "__main__":
    main()
